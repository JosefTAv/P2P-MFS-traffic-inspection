diff --git a/QDMA/DPDK/drivers/net/qdma/qdma.h b/QDMA/DPDK/drivers/net/qdma/qdma.h
index 66cc2bd..13d282b 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma.h
+++ b/QDMA/DPDK/drivers/net/qdma/qdma.h
@@ -479,17 +479,17 @@ int reclaim_tx_mbuf(struct qdma_tx_queue *txq,
 		uint16_t cidx, uint16_t free_cnt);
 int qdma_ul_extract_st_cmpt_info(void *ul_cmpt_entry, void *cmpt_info);

-/* Transmit API for Streaming mode */
-uint16_t qdma_xmit_pkts_vec(void *tx_queue,
-		struct rte_mbuf **tx_pkts, uint16_t nb_pkts);
-uint16_t qdma_xmit_pkts_st_vec(struct qdma_tx_queue *txq,
-		struct rte_mbuf **tx_pkts, uint16_t nb_pkts);
-
-/* Receive API for Streaming mode */
-uint16_t qdma_recv_pkts_vec(void *rx_queue,
-		struct rte_mbuf **rx_pkts, uint16_t nb_pkts);
-uint16_t qdma_recv_pkts_st_vec(struct qdma_rx_queue *rxq,
-		struct rte_mbuf **rx_pkts, uint16_t nb_pkts);
+// /* Transmit API for Streaming mode */
+// uint16_t qdma_xmit_pkts_vec(void *tx_queue,
+// 		struct rte_mbuf **tx_pkts, uint16_t nb_pkts);
+// uint16_t qdma_xmit_pkts_st_vec(struct qdma_tx_queue *txq,
+// 		struct rte_mbuf **tx_pkts, uint16_t nb_pkts);
+
+// /* Receive API for Streaming mode */
+// uint16_t qdma_recv_pkts_vec(void *rx_queue,
+// 		struct rte_mbuf **rx_pkts, uint16_t nb_pkts);
+// uint16_t qdma_recv_pkts_st_vec(struct qdma_rx_queue *rxq,
+// 		struct rte_mbuf **rx_pkts, uint16_t nb_pkts);

 void __rte_cold qdma_set_tx_function(struct rte_eth_dev *dev);
 void __rte_cold qdma_set_rx_function(struct rte_eth_dev *dev);
diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_access/eqdma_soft_access/eqdma_soft_access.c b/QDMA/DPDK/drivers/net/qdma/qdma_access/eqdma_soft_access/eqdma_soft_access.c
index 0108f7c..eb4eb92 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_access/eqdma_soft_access/eqdma_soft_access.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_access/eqdma_soft_access/eqdma_soft_access.c
@@ -2463,7 +2463,7 @@ int eqdma_set_default_global_csr(void *dev_hndl)
 		80, 96, 112, 128, 144, 160, 176, 192};
 	uint32_t buf_sz[QDMA_NUM_C2H_BUFFER_SIZES] = {4096, 256, 512, 1024,
 		2048, 3968, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 8192,
-		9018, 16384};
+		9618, 16384};
 	struct qdma_dev_attributes dev_cap;
 	uint32_t eqdma_ip_version;

diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_devops.c b/QDMA/DPDK/drivers/net/qdma/qdma_devops.c
index 8296c46..a3c6799 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_devops.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_devops.c
@@ -471,7 +471,7 @@ int qdma_dev_rx_queue_setup(struct rte_eth_dev *dev, uint16_t rx_queue_id,
 	/* Find Threshold index */
 	rxq->threshidx = index_of_array(qdma_dev->g_c2h_cnt_th,
 					QDMA_NUM_C2H_COUNTERS,
-					rx_conf->rx_thresh.wthresh);
+					rx_conf->rx_thresh.wthresh + 2);
 	if (rxq->threshidx < 0) {
 		PMD_DRV_LOG(WARNING, "Expected Threshold %d not found,"
 				" using the value %d at index 7\n",
diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c b/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
index 8796636..aecc379 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
@@ -41,12 +41,14 @@
 #include "qdma_rxtx.h"
 #include "qdma_devops.h"

+
 #if defined RTE_ARCH_X86_64
 #include <immintrin.h>
 #include <emmintrin.h>
 #define RTE_QDMA_DESCS_PER_LOOP (2)
 #endif

+
 /**
  * Poll the QDMA engine for transfer completion.
  *
@@ -132,8 +134,6 @@ static int qdma_extract_st_cmpt_info(void *ul_cmpt_entry, void *cmpt_info)
 	cmpt_data = (union qdma_ul_st_cmpt_ring *)(cmpt_info);

 	cmpt_data->data = cmpt_desc->data;
-	if (unlikely(!cmpt_desc->desc_used))
-		cmpt_data->length = 0;

 	return 0;
 }
@@ -1432,33 +1432,33 @@ uint16_t qdma_xmit_pkts(void *tx_queue, struct rte_mbuf **tx_pkts,
 void __rte_cold
 qdma_set_tx_function(struct rte_eth_dev *dev)
 {
-	struct qdma_pci_dev *qdma_dev = dev->data->dev_private;
-
-	if (rte_vect_get_max_simd_bitwidth() >= RTE_VECT_SIMD_128) {
-		PMD_DRV_LOG(DEBUG, "Using Vector Tx (port %d).",
-			dev->data->port_id);
-		qdma_dev->tx_vec_allowed = true;
-		dev->tx_pkt_burst = qdma_xmit_pkts_vec;
-	} else {
+	// struct qdma_pci_dev *qdma_dev = dev->data->dev_private;
+
+	// if (rte_vect_get_max_simd_bitwidth() >= RTE_VECT_SIMD_128) {
+	// 	PMD_DRV_LOG(DEBUG, "Using Vector Tx (port %d).",
+	// 		dev->data->port_id);
+	// 	qdma_dev->tx_vec_allowed = true;
+	// 	dev->tx_pkt_burst = qdma_xmit_pkts_vec;
+	// } else {
 		PMD_DRV_LOG(DEBUG, "Normal Rx will be used on port %d.",
 				dev->data->port_id);
 		dev->tx_pkt_burst = qdma_xmit_pkts;
-	}
+	// }
 }

 void __rte_cold
 qdma_set_rx_function(struct rte_eth_dev *dev)
 {
-	struct qdma_pci_dev *qdma_dev = dev->data->dev_private;
-
-	if (rte_vect_get_max_simd_bitwidth() >= RTE_VECT_SIMD_128) {
-		PMD_DRV_LOG(DEBUG, "Using Vector Rx (port %d).",
-			dev->data->port_id);
-		qdma_dev->rx_vec_allowed = true;
-		dev->rx_pkt_burst = qdma_recv_pkts_vec;
-	} else {
+	// struct qdma_pci_dev *qdma_dev = dev->data->dev_private;
+
+	// if (rte_vect_get_max_simd_bitwidth() >= RTE_VECT_SIMD_128) {
+	// 	PMD_DRV_LOG(DEBUG, "Using Vector Rx (port %d).",
+	// 		dev->data->port_id);
+	// 	qdma_dev->rx_vec_allowed = true;
+	// 	dev->rx_pkt_burst = qdma_recv_pkts_vec;
+	// } else {
 		PMD_DRV_LOG(DEBUG, "Normal Rx will be used on port %d.",
 				dev->data->port_id);
 		dev->rx_pkt_burst = qdma_recv_pkts;
-	}
+	// }
 }
diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_user.c b/QDMA/DPDK/drivers/net/qdma/qdma_user.c
index 9ce1dfc..4f819ea 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_user.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_user.c
@@ -59,12 +59,10 @@ int qdma_ul_extract_st_cmpt_info(void *ul_cmpt_entry, void *cmpt_info)
 	cmpt_desc = (union qdma_ul_st_cmpt_ring *)(ul_cmpt_entry);
 	cmpt_data = (union qdma_ul_st_cmpt_ring *)(cmpt_info);

-	if (unlikely(cmpt_desc->err || cmpt_desc->data_frmt))
+	if (unlikely(cmpt_desc->err))
 		return -1;

 	cmpt_data->data = cmpt_desc->data;
-	if (unlikely(!cmpt_desc->desc_used))
-		cmpt_data->length = 0;

 	return 0;
 }
@@ -80,7 +78,7 @@ int qdma_ul_extract_st_cmpt_info(void *ul_cmpt_entry, void *cmpt_info)
  */
 uint16_t qdma_ul_get_cmpt_pkt_len(void *ul_cmpt_entry)
 {
-	return ((union qdma_ul_st_cmpt_ring *)ul_cmpt_entry)->length;
+	return ((union qdma_ul_st_cmpt_ring *)ul_cmpt_entry)->pkt_len;
 }

 /**
@@ -173,35 +171,11 @@ int qdma_ul_update_st_h2c_desc(void *qhndl, uint64_t q_offloads,
 {
 	(void)q_offloads;
 	struct qdma_ul_st_h2c_desc *desc_info;
-	int nsegs = mb->nb_segs;
-	int pkt_segs = nsegs;

-	if (nsegs == 1) {
-		desc_info = get_st_h2c_desc(qhndl);
-		desc_info->len = rte_pktmbuf_data_len(mb);
-		desc_info->pld_len = desc_info->len;
-		desc_info->src_addr = mb->buf_iova + mb->data_off;
-		desc_info->flags = (S_H2C_DESC_F_SOP | S_H2C_DESC_F_EOP);
-		desc_info->cdh_flags = 0;
-		return 0;
-	}
-
-	while (nsegs && mb) {
-		desc_info = get_st_h2c_desc(qhndl);
-
-		desc_info->len = rte_pktmbuf_data_len(mb);
-		desc_info->pld_len = desc_info->len;
-		desc_info->src_addr = mb->buf_iova + mb->data_off;
-		desc_info->flags = 0;
-
-		desc_info->flags |= (nsegs == pkt_segs) ? S_H2C_DESC_F_SOP : 0;
-		desc_info->flags |= (nsegs == 1) ? S_H2C_DESC_F_EOP : 0;
-
-		desc_info->cdh_flags = 0;
-
-		nsegs--;
-		mb = mb->next;
-	}
+	desc_info = get_st_h2c_desc(qhndl);
+	desc_info->len = rte_pktmbuf_data_len(mb);
+	desc_info->meta_pkt_len = desc_info->len;
+	desc_info->src_addr = mb->buf_iova + mb->data_off;

 	return 0;
 }
@@ -283,7 +257,7 @@ int qdma_ul_process_immediate_data(void *cmpt_entry, uint16_t cmpt_desc_len,
 	struct qdma_ul_cmpt_ring *cmpt_desc =
 			(struct qdma_ul_cmpt_ring *)(cmpt_entry);

-	if (unlikely(cmpt_desc->err || cmpt_desc->data_frmt))
+	if (unlikely(cmpt_desc->err))
 		return -1;

 	cmpt_buff_ptr = (char *)cmpt_buff;
diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_user.h b/QDMA/DPDK/drivers/net/qdma/qdma_user.h
index 2bf475f..837c67c 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_user.h
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_user.h
@@ -49,40 +49,15 @@
   * This structure is specific for the example design.
   * Processing of this ring happens in qdma_rxtx.c.
   */
-union qdma_ul_st_cmpt_ring {
+union __attribute__ ((packed)) qdma_ul_st_cmpt_ring {
 	volatile uint64_t data;
-	struct {
-		/* For 2018.2 IP, this field determines the
-		 * Standard or User format of completion entry
-		 */
-		volatile uint32_t	data_frmt:1;
-
-		/* This field inverts every time PIDX wraps
-		 * the completion ring
-		 */
-		volatile uint32_t	color:1;
-
-		/* Indicates that C2H engine encountered
-		 * a descriptor error
-		 */
-		volatile uint32_t	err:1;
-
-		/* Indicates that the completion packet
-		 * consumes descriptor in C2H ring
-		 */
-		volatile uint32_t	desc_used:1;
-
-		/* Indicates length of the data packet */
-		volatile uint32_t	length:16;
-
-		/* Reserved field */
-		volatile uint32_t	user_rsv:4;
-
-		/* User logic defined data of
-		 * length based on CMPT entry
-		 * length
-		 */
-		volatile uint8_t	user_def[];
+	struct __attribute__ ((packed)) {
+		volatile uint32_t rsvd:1;
+		volatile uint32_t color:1;
+		volatile uint32_t err:1;
+		volatile uint32_t rsvd2:29;
+		volatile uint32_t pkt_len:16;
+		volatile uint32_t pkt_id:16;
 	};
 };

@@ -129,10 +104,10 @@ struct __attribute__ ((packed)) qdma_ul_st_c2h_desc
 /** ST H2C Descriptor **/
 struct __attribute__ ((packed)) qdma_ul_st_h2c_desc
 {
-	volatile uint16_t	cdh_flags;
-	volatile uint16_t	pld_len;
+	volatile uint16_t 	meta_pkt_len;
+	volatile uint16_t 	meta_unused;
 	volatile uint16_t	len;
-	volatile uint16_t	flags;
+	volatile uint16_t	rsvd;
 	volatile uint64_t	src_addr;
 };

 +
 +--
